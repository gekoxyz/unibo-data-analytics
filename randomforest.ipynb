{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4182f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c62e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device is available.\n",
      "Shape of the dataset: (148301, 145)\n",
      "Number of duplicates in the dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# Use the GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS device is available.\")\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    print(\"CUDA device is available.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"No GPU acceleration available.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Fix the seed to have deterministic behaviour\n",
    "def fix_random(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower\n",
    "\n",
    "SEED = 1337\n",
    "fix_random(SEED)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "DATASET_PATH = \"dataset_train/dataset.csv\"\n",
    "dataset = pd.read_csv(DATASET_PATH, delimiter=\",\")\n",
    "\n",
    "print(f\"Shape of the dataset: {dataset.shape}\")\n",
    "duplicates = dataset[dataset.duplicated()]\n",
    "print(f\"Number of duplicates in the dataset: {duplicates.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c067d2d",
   "metadata": {},
   "source": [
    "## Handling NaNs\n",
    "We drop columns with more than 20% of NaNs. We go from 145 to 89 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa6fe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_projected_additional_accrued_interest       99.564399\n",
      "hardship_loan_status_label                           99.432910\n",
      "hardship_type_label                                  99.431561\n",
      "hardship_end_date                                    99.431561\n",
      "hardship_duration_days                               99.430887\n",
      "hardship_last_payment_amount_total                   99.430887\n",
      "hardship_days_past_due                               99.430887\n",
      "hardship_reason_label                                99.430213\n",
      "hardship_start_date                                  99.429539\n",
      "hardship_payment_plan_start_date                     99.429539\n",
      "hardship_deferral_term_months                        99.428864\n",
      "hardship_status_label                                99.428190\n",
      "hardship_amount_total                                99.428190\n",
      "hardship_payoff_balance                              99.427516\n",
      "secondary_applicant_months_since_last_major_derog    98.374927\n",
      "settlement_term_months                               98.286593\n",
      "settlement_amount_total                              98.282547\n",
      "settlement_date                                      98.279850\n",
      "settlement_percentage                                98.279850\n",
      "settlement_status_label                              98.279175\n",
      "debt_settlement_flag_date                            98.278501\n",
      "secondary_applicant_revolving_utilization            95.318980\n",
      "secondary_applicant_open_active_installment_loans    95.239412\n",
      "secondary_applicant_inquiries_6m                     95.238737\n",
      "secondary_applicant_mortgage_accounts                95.234692\n",
      "secondary_applicant_fico_low                         95.234692\n",
      "secondary_applicant_fico_high                        95.234017\n",
      "secondary_applicant_collections_12m_ex_med           95.229971\n",
      "secondary_applicant_chargeoffs_12m                   95.228623\n",
      "secondary_applicant_earliest_credit_line             95.228623\n",
      "secondary_applicant_revolving_accounts               95.227274\n",
      "secondary_applicant_open_accounts                    95.225926\n",
      "joint_revolving_balance                              95.223228\n",
      "joint_income_verification_status                     94.862476\n",
      "joint_dti_ratio                                      94.652767\n",
      "joint_income_annual                                  94.647373\n",
      "months_since_last_public_record                      84.002805\n",
      "months_since_recent_bankcard_delinquency             77.155919\n",
      "months_since_last_major_derog                        74.106041\n",
      "months_since_recent_revolving_delinquency            67.409525\n",
      "next_payment_date                                    60.983405\n",
      "months_since_last_delinquency                        51.260612\n",
      "installment_utilization                              48.279513\n",
      "months_since_recent_installment_loan                 41.669308\n",
      "credit_inquiries_12m                                 39.895887\n",
      "total_balance_installment_loans                      39.892516\n",
      "finance_inquiries                                    39.891167\n",
      "overall_utilization                                  39.883076\n",
      "open_installment_loans_12m                           39.877681\n",
      "credit_union_trades_total                            39.865544\n",
      "open_installment_loans_24m                           39.862847\n",
      "bankcard_max_balance                                 39.862847\n",
      "open_revolving_accounts_12m                          39.860824\n",
      "open_accounts_6m                                     39.858126\n",
      "open_revolving_accounts_24m                          39.845315\n",
      "open_active_installment_loans                        39.842617\n",
      "dtype: float64\n",
      "Shape before dropping columns: (148301, 145)\n",
      "Shape after dropping columns: (148301, 88)\n"
     ]
    }
   ],
   "source": [
    "COLUMNS_TO_DROP_PERCENT = 20 # WHAT IF I PUT 50 INSTEAD?\n",
    "\n",
    "# Show the percentage of missing values\n",
    "missing_percentages = dataset.isna().mean() * 100\n",
    "cols_to_drop = missing_percentages[missing_percentages > COLUMNS_TO_DROP_PERCENT]\n",
    "print(cols_to_drop.sort_values(ascending=False))\n",
    "\n",
    "# drop columns with more than 20% of NaNs. We go from 145 to 89 features\n",
    "print(f\"Shape before dropping columns: {dataset.shape}\")\n",
    "dataset.drop(columns=cols_to_drop.index, inplace=True)\n",
    "# Drop also loan_title since it's redundant with loan_purpose_category\n",
    "dataset.drop(columns=\"loan_title\", inplace=True)\n",
    "print(f\"Shape after dropping columns: {dataset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a5417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "months_since_last_delinquency                        51.260612\n",
      "months_since_last_public_record                      84.002805\n",
      "next_payment_date                                    60.983405\n",
      "months_since_last_major_derog                        74.106041\n",
      "joint_income_annual                                  94.647373\n",
      "joint_dti_ratio                                      94.652767\n",
      "joint_income_verification_status                     94.862476\n",
      "open_accounts_6m                                     39.858126\n",
      "open_active_installment_loans                        39.842617\n",
      "open_installment_loans_12m                           39.877681\n",
      "open_installment_loans_24m                           39.862847\n",
      "months_since_recent_installment_loan                 41.669308\n",
      "total_balance_installment_loans                      39.892516\n",
      "installment_utilization                              48.279513\n",
      "open_revolving_accounts_12m                          39.860824\n",
      "open_revolving_accounts_24m                          39.845315\n",
      "bankcard_max_balance                                 39.862847\n",
      "overall_utilization                                  39.883076\n",
      "finance_inquiries                                    39.891167\n",
      "credit_union_trades_total                            39.865544\n",
      "credit_inquiries_12m                                 39.895887\n",
      "months_since_recent_bankcard_delinquency             77.155919\n",
      "months_since_recent_revolving_delinquency            67.409525\n",
      "joint_revolving_balance                              95.223228\n",
      "secondary_applicant_fico_low                         95.234692\n",
      "secondary_applicant_fico_high                        95.234017\n",
      "secondary_applicant_earliest_credit_line             95.228623\n",
      "secondary_applicant_inquiries_6m                     95.238737\n",
      "secondary_applicant_mortgage_accounts                95.234692\n",
      "secondary_applicant_open_accounts                    95.225926\n",
      "secondary_applicant_revolving_utilization            95.318980\n",
      "secondary_applicant_open_active_installment_loans    95.239412\n",
      "secondary_applicant_revolving_accounts               95.227274\n",
      "secondary_applicant_chargeoffs_12m                   95.228623\n",
      "secondary_applicant_collections_12m_ex_med           95.229971\n",
      "secondary_applicant_months_since_last_major_derog    98.374927\n",
      "hardship_type_label                                  99.431561\n",
      "hardship_reason_label                                99.430213\n",
      "hardship_status_label                                99.428190\n",
      "hardship_deferral_term_months                        99.428864\n",
      "hardship_amount_total                                99.428190\n",
      "hardship_start_date                                  99.429539\n",
      "hardship_end_date                                    99.431561\n",
      "hardship_payment_plan_start_date                     99.429539\n",
      "hardship_duration_days                               99.430887\n",
      "hardship_days_past_due                               99.430887\n",
      "hardship_loan_status_label                           99.432910\n",
      "original_projected_additional_accrued_interest       99.564399\n",
      "hardship_payoff_balance                              99.427516\n",
      "hardship_last_payment_amount_total                   99.430887\n",
      "debt_settlement_flag_date                            98.278501\n",
      "settlement_status_label                              98.279175\n",
      "settlement_date                                      98.279850\n",
      "settlement_amount_total                              98.282547\n",
      "settlement_percentage                                98.279850\n",
      "settlement_term_months                               98.286593\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(cols_to_drop.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c494e4f",
   "metadata": {},
   "source": [
    "## Categorical data conversion and dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fbddffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before converting categorical data\n",
      "Categorical columns:\n",
      "Index(['loan_contract_term_months', 'borrower_profile_employment_length',\n",
      "       'borrower_housing_ownership_status',\n",
      "       'borrower_income_verification_status', 'loan_issue_date',\n",
      "       'loan_status_current_code', 'loan_payment_plan_flag',\n",
      "       'loan_purpose_category', 'borrower_address_zip',\n",
      "       'borrower_address_state', 'credit_history_earliest_line',\n",
      "       'listing_initial_status', 'last_payment_date', 'last_credit_pull_date',\n",
      "       'application_type_label', 'hardship_flag_indicator',\n",
      "       'disbursement_method_type', 'debt_settlement_flag_indicator', 'grade'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = dataset.select_dtypes(include=['number']).columns\n",
    "print(\"Before converting categorical data\")\n",
    "categorical_cols = dataset.select_dtypes(include=['object', 'category']).columns\n",
    "print(f\"Categorical columns:\\n{categorical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940b49d",
   "metadata": {},
   "source": [
    "### Stateless categorical data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0874022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stateless transformations (can be done on train and test set independently)\n",
    "dataset[\"grade\"] = dataset[\"grade\"].map({'A': 6, 'B': 5, 'C': 4, 'D': 3, 'E': 2, 'F': 1, 'G': 0})\n",
    "\n",
    "def extract_int_value_from_column(column_name):\n",
    "    dataset[column_name] = dataset[column_name].str.extract(r\"(\\d+)\").astype(\"Int64\")\n",
    "\n",
    "extract_int_value_from_column(\"loan_contract_term_months\")\n",
    "extract_int_value_from_column(\"borrower_profile_employment_length\")\n",
    "\n",
    "# DROP FOR TREES, USE FOR DEEP ENTWORKS\n",
    "# extract_int_value_from_column(\"borrower_address_zip\")\n",
    "dataset.drop(columns=\"borrower_address_zip\", inplace=True)\n",
    "\n",
    "def convert_mm_yyyy_to_year_sine_cosine(column_name):\n",
    "    # Convert mm-yyyy to the year and month encoded in sine/cosine representation so that dec 1999 and jan 2000 are close\n",
    "    dataset[column_name] = pd.to_datetime(dataset[column_name], format='%b-%Y')\n",
    "    date_col = dataset[column_name].dt # avoid creating temporary object\n",
    "    dataset[f\"{column_name}_year\"] = date_col.year\n",
    "    angle = 2 * np.pi * date_col.month / 12\n",
    "    dataset[f\"{column_name}_month_sin\"] = np.sin(angle)\n",
    "    dataset[f\"{column_name}_month_cos\"] = np.cos(angle)\n",
    "    dataset.drop(columns=[column_name], inplace=True)\n",
    "\n",
    "convert_mm_yyyy_to_year_sine_cosine(\"loan_issue_date\")\n",
    "convert_mm_yyyy_to_year_sine_cosine(\"credit_history_earliest_line\")\n",
    "convert_mm_yyyy_to_year_sine_cosine(\"last_payment_date\")\n",
    "convert_mm_yyyy_to_year_sine_cosine(\"last_credit_pull_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b326b1",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c55bd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "(118640, 94)\n",
      "(118640,)\n",
      "Validation set\n",
      "(29661, 94)\n",
      "(29661,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.drop(columns=[\"grade\"])\n",
    "y = dataset[\"grade\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "print(\"Training set\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation set\")\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94697cfd",
   "metadata": {},
   "source": [
    "### Stateful categorical data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dda35562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stateful transformations (with statistics calculated on training set and applied on both sets)\n",
    "\n",
    "# We transform the binary categorical cols with 1 and 0. We use 1 for the least frequent data\n",
    "# because it carries more signal\n",
    "binary_categorical_cols = [\"loan_payment_plan_flag\", \"listing_initial_status\", \"application_type_label\",\n",
    "               \"hardship_flag_indicator\", \"disbursement_method_type\", \"debt_settlement_flag_indicator\"]\n",
    "binary_categorical_cols_feature_map = {}\n",
    "\n",
    "# FIT: Calculate mode only on X_train\n",
    "# TRANSFORM: Apply to X_train and x_val using the mode of X_train\n",
    "for col in binary_categorical_cols:\n",
    "    col_mode = X_train[col].mode()[0]\n",
    "    binary_categorical_cols_feature_map[col] = col_mode\n",
    "    X_train[col] = (X_train[col] != col_mode).astype(\"Int64\")\n",
    "    X_val[col] = (X_val[col] != col_mode).astype(\"Int64\")\n",
    "\n",
    "\n",
    "one_hot_encoding_cols = [\"borrower_housing_ownership_status\", \"borrower_income_verification_status\",\n",
    "                       \"loan_status_current_code\", \"loan_purpose_category\", \"borrower_address_state\"]\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "encoder.fit(X_train[one_hot_encoding_cols])\n",
    "one_hot_encoding_feature_names = encoder.get_feature_names_out(one_hot_encoding_cols)\n",
    "\n",
    "# Apply one-hot encoding to the training set\n",
    "X_train_encoded = pd.DataFrame(encoder.transform(X_train[one_hot_encoding_cols]), columns=one_hot_encoding_feature_names, index=X_train.index)\n",
    "X_train = pd.concat([X_train.drop(columns=one_hot_encoding_cols), X_train_encoded], axis=1)\n",
    "\n",
    "# Apply one-hot encoding to the test set\n",
    "X_val_encoded = pd.DataFrame(encoder.transform(X_val[one_hot_encoding_cols]), columns=one_hot_encoding_feature_names, index=X_val.index)\n",
    "X_val = pd.concat([X_val.drop(columns=one_hot_encoding_cols), X_val_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a28873fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After converting categorical data\n",
      "Train Shape: (118640, 172)\n",
      "Categorical columns:\n",
      "Index([], dtype='object')\n",
      "Test Shape:  (29661, 172)\n",
      "Categorical columns:\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"After converting categorical data\")\n",
    "print(f\"Train Shape: {X_train.shape}\")\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "print(f\"Categorical columns:\\n{categorical_cols}\")\n",
    "print(f\"Test Shape:  {X_val.shape}\")\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "print(f\"Categorical columns:\\n{categorical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a20e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('rf', RandomForestClassifier(max_depth=50, class_weight='balanced', n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "bacc = balanced_accuracy_score(y_val, y_pred)\n",
    "print(f\"Balanced accuracy: {bacc}\")\n",
    "f1 = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "print(f\"F1 score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17be71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8591753481001989\n",
      "Balanced accuracy: 0.7954629216584609\n",
      "F1 score: 0.8566987148664283\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

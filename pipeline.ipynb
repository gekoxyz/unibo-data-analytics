{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "32640029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88640189",
   "metadata": {},
   "source": [
    "# load the dataset and fix values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a9a6eb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device is available.\n",
      "Shape of the dataset: (148301, 145)\n",
      "Number of duplicates in the dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# Use the GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS device is available.\")\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    print(\"CUDA device is available.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"No GPU acceleration available.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Fix the seed to have deterministic behaviour\n",
    "def fix_random(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower\n",
    "\n",
    "SEED = 1337\n",
    "fix_random(SEED)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "DATASET_PATH = \"dataset_train/dataset.csv\"\n",
    "dataset = pd.read_csv(DATASET_PATH, delimiter=\",\")\n",
    "\n",
    "print(f\"Shape of the dataset: {dataset.shape}\")\n",
    "duplicates = dataset[dataset.duplicated()]\n",
    "print(f\"Number of duplicates in the dataset: {duplicates.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae26d9",
   "metadata": {},
   "source": [
    "## split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dbe853ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=[\"grade\"])\n",
    "y = dataset[\"grade\"].map({\"A\": 6, \"B\": 5, \"C\": 4, \"D\": 3, \"E\": 2, \"F\": 1, \"G\": 0})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a61d55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extracts integers from strings using regex\"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in X.columns:\n",
    "            X[col] = X[col].astype(str).str.extract(r\"(\\d+)\").astype(float)\n",
    "        return X\n",
    "\n",
    "class CyclicalDateEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Converts mm-yyyy to year + sine/cosine month encoding.\"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in X.columns:\n",
    "            date_series = pd.to_datetime(X[col], format=\"%b-%Y\", errors=\"coerce\")\n",
    "            angle = 2 * np.pi * date_series.dt.month / 12\n",
    "\n",
    "            X[f\"{col}_year\"] = date_series.dt.year\n",
    "            X[f\"{col}_month_sin\"] = np.sin(angle)\n",
    "            X[f\"{col}_month_cos\"] = np.cos(angle)\n",
    "            \n",
    "            X.drop(columns=[col], inplace=True)\n",
    "        return X\n",
    "    \n",
    "class BinaryModeEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\"Encodes 0 if value is mode, 1 if not\"\"\"\n",
    "    def __init__(self):\n",
    "        self.modes_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calculate mode for each column and store it\n",
    "        for col in X.columns:\n",
    "            self.modes_[col] = X[col].mode()[0]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        for col, mode in self.modes_.items():\n",
    "            # Apply: 1 if NOT the mode (least frequent), 0 if mode\n",
    "            X_copy[col] = (X_copy[col] != mode).astype(int)\n",
    "        return X_copy\n",
    "    \n",
    "class HighMissingDropper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Drops columns with high missing percentage. Fits only on training data.\"\"\"\n",
    "    \n",
    "    def __init__(self, threshold=20):\n",
    "        self.threshold = threshold\n",
    "        self.cols_to_drop_ = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calculate missing percentages only on training data\n",
    "        missing_percentages = X.isna().mean() * 100\n",
    "        self.cols_to_drop_ = missing_percentages[missing_percentages > self.threshold].index.tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        return X.drop(columns=[col for col in self.cols_to_drop_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "821899ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration FOR RANDOM FOREST\n",
    "redundant_cols = ['loan_title']\n",
    "binary_cols = [\"loan_payment_plan_flag\", \"listing_initial_status\", \"application_type_label\",\n",
    "               \"hardship_flag_indicator\", \"disbursement_method_type\", \"debt_settlement_flag_indicator\"]\n",
    "one_hot_encoding_cols = [\"borrower_housing_ownership_status\", \"borrower_income_verification_status\",\n",
    "                       \"loan_status_current_code\", \"loan_purpose_category\", \"borrower_address_state\"]\n",
    "extract_fields = [\"loan_contract_term_months\", \"borrower_profile_employment_length\", \"borrower_address_zip\"]\n",
    "date_fields = [\"loan_issue_date\", \"credit_history_earliest_line\", \"last_payment_date\", \"last_credit_pull_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa2448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8652\n",
      "Balanced Accuracy: 0.8016\n",
      "F1 score: 0.8627\n"
     ]
    }
   ],
   "source": [
    "# Build the column transformer with proper imputation per data type\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Extract numeric from text fields \n",
    "        ('extract', NumericExtractor(), extract_fields),\n",
    "        \n",
    "        # Date encoding (creates numeric features)\n",
    "        ('date', CyclicalDateEncoder(), date_fields),\n",
    "        \n",
    "        # Binary encoding (no imputation needed - just mode encoding)\n",
    "        ('binary', BinaryModeEncoder(), binary_cols),\n",
    "        \n",
    "        # Categorical with proper imputation BEFORE encoding\n",
    "        ('categorical', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), one_hot_encoding_cols),\n",
    "        \n",
    "        # Drop redundant columns\n",
    "        ('drop_redundant', 'drop', redundant_cols)\n",
    "    ], remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('dropper', HighMissingDropper(threshold=20)),\n",
    "    ('prep', preprocessor),\n",
    "    ('rf', RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=42))\n",
    "])\n",
    "\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "y_pred = full_pipeline.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "bacc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"Balanced Accuracy: {bacc:.4f}\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "print(f\"F1 score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b4a687",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f496535",
   "metadata": {},
   "source": [
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('extract', NumericExtractor(extract_cols=extract_fields), extract_fields),\n",
    "    ('date', CyclicalDateEncoder(date_cols=date_fields), date_fields),\n",
    "    ('binary', BinaryModeEncoder(columns=binary_cols), binary_cols),\n",
    "    ('ohe', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), one_hot_encoding_cols),\n",
    "    ('drop_cols', 'drop', cols_to_drop)\n",
    "], remainder='passthrough') # This keeps existing numeric columns\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('imputer', SimpleImputer()),       # Placeholder, set by grid\n",
    "    ('scaler', StandardScaler()),       # Placeholder, set by grid\n",
    "    # ('pca', PCA()),                     # Placeholder, set by grid\n",
    "    ('rf', RandomForestClassifier(max_depth=50, class_weight='balanced', n_jobs=-1))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    # Path A: Test PCA (Must have Imputer and Scaler)\n",
    "    {\n",
    "        'imputer': [SimpleImputer(strategy='median')],\n",
    "        'scaler': [StandardScaler()],   # CRITICAL: PCA requires scaling\n",
    "    },\n",
    "    # Path B: Test \"Raw\" data (no PCA, Scaling optional but usually good)\n",
    "    {\n",
    "        'imputer': [SimpleImputer(strategy='median')],\n",
    "        'scaler': ['passthrough'],      # RF doesn't strictly need scaling\n",
    "    },\n",
    "    # Path C: No PCA, no scaling, no variable imputing\n",
    "    {\n",
    "        'imputer': ['passthrough'],\n",
    "        'scaler': ['passthrough'],\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(full_pipeline, param_grid, cv=5, scoring='balanced_accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Setup: {grid.best_params_}\")\n",
    "print(f\"Best Score: {grid.best_score_}\")\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ccf46a",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

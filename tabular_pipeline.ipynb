{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32640029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from pytorch_tabular.models import TabNetModelConfig\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig, ModelConfig\n",
    "from pytorch_tabular import TabularModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88640189",
   "metadata": {},
   "source": [
    "# load the dataset and fix values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9a6eb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device is available.\n",
      "Shape of the dataset: (148301, 145)\n",
      "Number of duplicates in the dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# Use the GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS device is available.\")\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    print(\"CUDA device is available.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"No GPU acceleration available.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Fix the seed to have deterministic behaviour\n",
    "def fix_random(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower\n",
    "\n",
    "SEED = 1337\n",
    "fix_random(SEED)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "DATASET_PATH = \"dataset_train/dataset.csv\"\n",
    "dataset = pd.read_csv(DATASET_PATH, delimiter=\",\")\n",
    "\n",
    "print(f\"Shape of the dataset: {dataset.shape}\")\n",
    "duplicates = dataset[dataset.duplicated()]\n",
    "print(f\"Number of duplicates in the dataset: {duplicates.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae26d9",
   "metadata": {},
   "source": [
    "## split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "695537cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping columns: (148301, 145)\n",
      "Shape after dropping columns: (148301, 88)\n"
     ]
    }
   ],
   "source": [
    "COLUMNS_TO_DROP_PERCENT = 20\n",
    "\n",
    "# Show the percentage of missing values\n",
    "missing_percentages = dataset.isna().mean() * 100\n",
    "cols_to_drop = missing_percentages[missing_percentages > COLUMNS_TO_DROP_PERCENT]\n",
    "# drop columns with more than 20% of NaNs. We go from 145 to 89 features\n",
    "print(f\"Shape before dropping columns: {dataset.shape}\")\n",
    "dataset.drop(columns=cols_to_drop.index, inplace=True)\n",
    "# Drop also loan_title since it's redundant with loan_purpose_category\n",
    "dataset.drop(columns=\"loan_title\", inplace=True)\n",
    "print(f\"Shape after dropping columns: {dataset.shape}\")\n",
    "\n",
    "for col in dataset.select_dtypes(include=\"number\").columns:\n",
    "    dataset[col] = dataset[col].fillna(dataset[col].median())\n",
    "\n",
    "for col in dataset.select_dtypes(include=[\"object\", \"category\"]).columns:\n",
    "    dataset[col] = dataset[col].fillna(\"MISSING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbe853ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=[\"grade\"])\n",
    "y = dataset[\"grade\"].map({\"A\": 6, \"B\": 5, \"C\": 4, \"D\": 3, \"E\": 2, \"F\": 1, \"G\": 0})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbdd3195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns:\n",
      "['loan_contract_term_months', 'borrower_profile_employment_length', 'borrower_housing_ownership_status', 'borrower_income_verification_status', 'loan_issue_date', 'loan_status_current_code', 'loan_payment_plan_flag', 'loan_purpose_category', 'borrower_address_zip', 'borrower_address_state', 'credit_history_earliest_line', 'listing_initial_status', 'last_payment_date', 'last_credit_pull_date', 'application_type_label', 'hardship_flag_indicator', 'disbursement_method_type', 'debt_settlement_flag_indicator']\n",
      "Numerical columns:\n",
      "['loan_contract_approved_amount', 'loan_portfolio_total_funded', 'investor_side_funded_amount', 'loan_contract_interest_rate', 'loan_payment_installments_count', 'borrower_income_annual', 'borrower_dti_ratio', 'credit_delinquencies_2yrs', 'fico_score_low_bound', 'fico_score_high_bound', 'credit_inquiries_6m', 'credit_open_accounts', 'credit_public_records', 'revolving_balance', 'revolving_utilization', 'credit_total_accounts', 'outstanding_principal_balance', 'outstanding_principal_investor_side', 'total_payment_received', 'total_payment_investor_side', 'total_received_principal', 'total_received_interest', 'total_received_late_fees', 'recoveries_cash', 'collection_recovery_fee', 'last_payment', 'last_fico_score_high_bound', 'last_fico_score_low_bound', 'collections_12m_ex_med', 'platform_policy_code_id', 'accounts_now_delinquent', 'total_collection_amount', 'total_current_balance', 'total_revolving_high_credit_limit', 'accounts_open_past_24m', 'average_current_balance', 'bankcard_open_to_buy', 'bankcard_utilization', 'chargeoffs_within_12m', 'delinquency_amount', 'months_since_oldest_installment_acct', 'months_since_oldest_revolving_acct', 'months_since_recent_revolving_acct', 'months_since_recent_trade_line', 'mortgage_accounts', 'months_since_recent_bankcard', 'months_since_recent_inquiry', 'accounts_ever_120dpd', 'active_bankcard_tradelines', 'active_revolving_tradelines', 'bankcard_satisfactory_accounts', 'bankcard_tradelines', 'installment_tradelines', 'open_revolving_tradelines', 'revolving_accounts', 'revolving_tradelines_balance_gt_0', 'satisfactory_accounts', 'tradelines_120dpd_2m', 'tradelines_30dpd', 'tradelines_90dpd_24m', 'tradelines_open_past_12m', 'tradelines_never_delinquent_ratio', 'bankcard_util_gt_75_ratio', 'public_record_bankruptcies', 'tax_liens_total', 'total_high_credit_limit', 'total_balance_ex_mortgage', 'total_bankcard_credit_limit', 'total_installment_high_credit_limit']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Categorical columns:\\n{categorical_cols}\")\n",
    "numerical_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "print(f\"Numerical columns:\\n{numerical_cols}\")\n",
    "\n",
    "train_df = X_train.copy()\n",
    "train_df['grade'] = y_train\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df['grade'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dae203",
   "metadata": {},
   "source": [
    "```python\n",
    "param_dist_tabnet = {\n",
    "    'n_d': [16, 32, 64], \n",
    "    'n_a': [16, 32, 64],\n",
    "    'gamma': [1.0, 1.2, 1.5],\n",
    "    'n_steps': [3, 5], \n",
    "    'lambda_sparse': [1e-3, 1e-4]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720ef04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-30 15:59:58,645 - {pytorch_tabular.tabular_model:145} - INFO - Experiment Tracking is turned off\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Data Config\n",
    "data_config = DataConfig(\n",
    "    target=[\"grade\"], \n",
    "    continuous_cols=numerical_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    "    normalize_continuous_features=True\n",
    ")\n",
    "\n",
    "# 2. Trainer Config\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=512,\n",
    "    max_epochs=50,\n",
    "    early_stopping_patience=5,\n",
    "    accelerator=\"auto\", # auto Uses GPU if available\n",
    ")\n",
    "\n",
    "# 3. Model Config (Using a standard Category Embedding Model)\n",
    "model_config = TabNetModelConfig(\n",
    "    task=\"classification\",\n",
    "    metrics=[\"accuracy\", \"f1_score\"]\n",
    ")\n",
    "\n",
    "# 4. Initialize the Tabular Model\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=OptimizerConfig(),\n",
    "    trainer_config=trainer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df9b7022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "2026-01-30 15:59:58,666 - {pytorch_tabular.tabular_model:547} - INFO - Preparing the DataLoaders\n",
      "2026-01-30 15:59:58,822 - {pytorch_tabular.tabular_datamodule:527} - INFO - Setting up the datamodule for classification task\n",
      "2026-01-30 15:59:59,346 - {pytorch_tabular.tabular_model:598} - INFO - Preparing the Model: TabNetModel\n",
      "2026-01-30 15:59:59,517 - {pytorch_tabular.tabular_model:341} - INFO - Preparing the Trainer\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/Users/geko/unibo/data_analytics/project/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/setup.py:175: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "2026-01-30 15:59:59,532 - {pytorch_tabular.tabular_model:677} - INFO - Training Started\n",
      "/Users/geko/unibo/data_analytics/project/.venv/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:881: Checkpoint directory /Users/geko/unibo/data_analytics/project/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _embedding_layer │ Identity         │      0 │ train │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ TabNetBackbone   │  120 K │ train │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Identity         │      0 │ train │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │     0 │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Identity         │      0 │ train │     0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabNetBackbone   │  120 K │ train │     0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Identity         │      0 │ train │     0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │     0 │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 120 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 120 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 126                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 120 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 120 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 126                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c6f4d29c9141349794da58307eed1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/geko/unibo/data_analytics/project/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/da\n",
       "ta_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing\n",
       "the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/geko/unibo/data_analytics/project/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/da\n",
       "ta_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing\n",
       "the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/geko/unibo/data_analytics/project/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: \n",
       "UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
       "  warnings.warn(warn_msg)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/geko/unibo/data_analytics/project/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: \n",
       "UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
       "  warnings.warn(warn_msg)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/geko/unibo/data_analytics/project/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/da\n",
       "ta_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/geko/unibo/data_analytics/project/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/da\n",
       "ta_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-30 16:11:33,524 - {pytorch_tabular.tabular_model:690} - INFO - Training the model completed\n",
      "2026-01-30 16:11:33,524 - {pytorch_tabular.tabular_model:1531} - INFO - Loading the best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91314902102c433580aef2fb25664d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geko/unibo/data_analytics/project/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8274838924407959     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_f1_score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8274838924407959     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4214223325252533     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_loss_0        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4214223325252533     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8274838924407959    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_f1_score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8274838924407959    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4214223325252533    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_loss_0       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4214223325252533    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_loss_0': 0.4214223325252533, 'test_loss': 0.4214223325252533, 'test_accuracy': 0.8274838924407959, 'test_f1_score': 0.8274838924407959}]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "tabular_model.fit(train=train_df, validation=test_df)\n",
    "\n",
    "# Evaluate\n",
    "result = tabular_model.evaluate(test_df)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
